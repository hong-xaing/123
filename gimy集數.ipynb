{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93c303e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://gimy.app/cat/4--------1---.html\"\n",
    "res = requests.get(url)\n",
    "soup = BeautifulSoup(res.text,\"lxml\")\n",
    "# print(soup)\n",
    "html = soup.find_all(\"div\",class_=\"box-video-list\")\n",
    "print(html)\n",
    "# (\"div\",class_=\"title\")(\"h5\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdb595f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "# url = \"https://gimy.app/cat/4--------1---.html\"\n",
    "\n",
    "# print(soup)\n",
    "# html = soup.find_all(\"div\",class_=\"box-video-list\")[0]\n",
    "# print(html)\n",
    "# html2 = soup.find_all(\"div\",class_=\"title\")\n",
    "\n",
    "# print(html2)\n",
    "page = 1\n",
    "while True:\n",
    "    print(\"現在抓到第\"+str(page)+\"頁\")\n",
    "    url = \"https://gimy.app/cat/4--------\"+str(page)+\"---.html\"\n",
    "    res = requests.get(url)\n",
    "    soup = BeautifulSoup(res.text,\"lxml\")\n",
    "    html2 = soup.find_all(\"div\",class_=\"box-video-list\")[0].find_all(\"div\",class_=\"title\")\n",
    "#     print(html2)\n",
    "    for href in html2:\n",
    "        a_teg = href.find(\"h5\").find(\"a\")\n",
    "    #     print(a_teg)\n",
    "        if a_teg:\n",
    "            link = a_teg[\"href\"]\n",
    "            title = a_teg[\"title\"]\n",
    "    #         print(link)\n",
    "            print(f\"標題:{title},連結:{link}\")\n",
    "        \n",
    "    page += 1\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8771831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "現在抓到第1頁\n",
      "現在抓到第2頁\n",
      "現在抓到第3頁\n",
      "現在抓到第4頁\n",
      "現在抓到第5頁\n",
      "現在抓到第6頁\n",
      "現在抓到第7頁\n",
      "現在抓到第8頁\n",
      "現在抓到第9頁\n",
      "現在抓到第10頁\n",
      "現在抓到第11頁\n",
      "現在抓到第12頁\n",
      "現在抓到第13頁\n",
      "現在抓到第14頁\n",
      "現在抓到第15頁\n",
      "現在抓到第16頁\n",
      "現在抓到第17頁\n",
      "現在抓到第18頁\n",
      "現在抓到第19頁\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from openpyxl import Workbook\n",
    "\n",
    "# 创建一个新的工作簿\n",
    "wb = Workbook()\n",
    "# 选择活动的工作表\n",
    "ws = wb.active\n",
    "# 添加标题行\n",
    "ws.append([\"標題\", \"連結\"])\n",
    "\n",
    "page = 1\n",
    "while page != 20:\n",
    "    print(\"現在抓到第\" + str(page) + \"頁\")\n",
    "    url = \"https://gimy.app/cat/4--------\" + str(page) + \"---.html\"\n",
    "    res = requests.get(url)\n",
    "    soup = BeautifulSoup(res.text, \"lxml\")\n",
    "\n",
    "    # 找到包含链接的元素\n",
    "    html2_list = soup.find_all(\"div\", class_=\"box-video-list\")[0].find_all(\"div\", class_=\"title\")\n",
    "\n",
    "    # 遍历每个包含链接的元素并提取链接\n",
    "    for href in html2_list:\n",
    "        a_tag = href.find(\"h5\").find(\"a\")\n",
    "        if a_tag:\n",
    "            link = a_tag[\"href\"]\n",
    "            title_text = a_tag[\"title\"]\n",
    "            # 将数据添加到工作表\n",
    "            ws.append([title_text, \"https://gimy.app/\"+link])\n",
    "\n",
    "    page += 1\n",
    "    time.sleep(5)\n",
    "\n",
    "# 保存工作簿到文件\n",
    "    wb.save(\"gimy抓取的数据1.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1e3985",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# 初始化页面计数器\n",
    "page = 1\n",
    "\n",
    "while True:\n",
    "    # 构建当前页面的URL\n",
    "    url = f\"https://gimy.app/cat/4--------{page}---.html\"\n",
    "    \n",
    "    # 发送HTTP请求\n",
    "    res = requests.get(url)\n",
    "    \n",
    "    # 检查是否成功获取页面\n",
    "    if res.status_code != 200:\n",
    "        break  # 如果无法获取页面，退出循环\n",
    "    \n",
    "    soup = BeautifulSoup(res.text, \"lxml\")\n",
    "    print(f\"现在抓到第 {page} 页\")\n",
    "    \n",
    "    # 找到包含链接的元素\n",
    "    html2_list = soup.find_all(\"div\", class_=\"layout-box clearfix\")\n",
    "    \n",
    "    # 检查是否有足够的匹配项\n",
    "    if len(html2_list) >= 2:\n",
    "        # 遍历匹配项，提取第二个匹配项\n",
    "        for i in range(1, len(html2_list)):\n",
    "            match = html2_list[i]\n",
    "            a_tag = match.find(\"h5\").find(\"a\")\n",
    "            if a_tag:\n",
    "                link = a_tag[\"href\"]\n",
    "                title = a_tag[\"title\"]\n",
    "                print(f\"标题: {title}, 链接: {link}\")\n",
    "    \n",
    "    page += 1\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0e5c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "page = 1\n",
    "while True:\n",
    "    print(\"現在抓到第\"+str(page)+\"頁\")\n",
    "    url = \"https://gimy.app/cat/4--------\"+str(page)+\"---.html\"\n",
    "    res = requests.get(url)\n",
    "    soup = BeautifulSoup(res.text,\"lxml\")\n",
    "    \n",
    "    # 使用 CSS 选择器来找到所需元素\n",
    "    titles = soup.select(\".box-video-list .title h5 a\")\n",
    "    \n",
    "    for title in titles:\n",
    "        link = title[\"href\"]\n",
    "        title_text = title[\"title\"]\n",
    "        print(f\"標題: {title_text}, 連結: {link}\")\n",
    "        \n",
    "    page += 1\n",
    "    time.sleep(2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
